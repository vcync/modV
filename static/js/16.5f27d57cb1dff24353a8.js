webpackJsonp([16],{855:function(n,e){n.exports='/*{\n  "DESCRIPTION": "This commented shader explains how transform the camera rays so that the output is rendered in equirectangular or fisheye format.  Can be used in domes or other immersive environments. Hold mouse for equirectangular view and move mouse to rotate camera. ",\n  "CREDIT": "WilstonOreo",\n  "CATEGORIES": [\n    "dome",\n    "raymarching",\n    "tutorial",\n    "fisheye",\n    "equirectangular"\n  ],\n  "INPUTS": [\n    {\n      "LABEL": "Mouse X",\n      "NAME": "mX",\n      "TYPE": "float",\n      "DEFAULT": 0.5,\n      "MIN": 0.0,\n      "MAX": 1.0\n    },\n    {\n      "LABEL": "Mouse Y",\n      "NAME": "mY",\n      "TYPE": "float",\n      "DEFAULT": 0.5,\n      "MIN": 0.0,\n      "MAX": 1.0\n    },\n    {\n      "LABEL": "Mouse Z",\n      "NAME": "mZ",\n      "TYPE": "float",\n      "DEFAULT": 0.5,\n      "MIN": 0.0,\n      "MAX": 1.0\n    },\n    {\n      "LABEL": "Mouse W",\n      "NAME": "mW",\n      "TYPE": "float",\n      "DEFAULT": 0.5,\n      "MIN": 0.0,\n      "MAX": 1.0\n    }\n  ]\n}*/\n\nvec3 iResolution = vec3(RENDERSIZE, 1.);\nvec4 iMouse = vec4(mX*RENDERSIZE.x, mY*RENDERSIZE.y, mZ*RENDERSIZE.x, mW*RENDERSIZE.y);\nfloat iTime = TIME;\n\n// Licensed under Creative Commons 3.0 Share Alike License\n// Based on dila\'s ray marching tutorial:\n// https://www.shadertoy.com/view/XdKGWm\n\n// (C) 2016-2017 by WilstonOreo http://omnido.me\n\n\n#define MAP_EQUIRECTANGULAR 0\n#define MAP_FISHEYE 1\n\n// Display equirectangular view when clicked.\n\nconst float speed = 0.5;\n\n\nint map_mode() {\n    return (iMouse.w > 0.0) ? MAP_FISHEYE : MAP_EQUIRECTANGULAR;\n}\n\n\n// Camera rotation with mouse\n\nfloat camera_yaw() {\n  return iMouse.x / iResolution.x * 360.0;\n}\n\nfloat camera_pitch() {\n  return iMouse.y / iResolution.y * 360.0;\n}\n\n\nconst float camera_roll = 0.0;\nconst float sphere_size = 0.25;\n\n\n//////////////////////////////////////////////////\n// Code section for spherical translation\n\nconst float PI = 3.14159265358979323846264;\n\n/// Convert degrees to radians\nfloat deg2rad(in float deg)\n{\n  return deg * PI / 180.0;\n}\n\n/// Calculates the rotation matrix of a rotation around X axis with an angle in radians\nmat3 rotateAroundX( in float angle )\n{\n  float s = sin(angle);\n  float c = cos(angle);\n  return mat3(1.0,0.0,0.0,\n              0.0,  c, -s,\n              0.0,  s,  c);\n}\n\n// Calculates the rotation matrix of a rotation around Y axis with an angle in radians\nmat3 rotateAroundY( in float angle )\n{\n  float s = sin(angle);\n  float c = cos(angle);\n  return mat3(  c,0.0,  s,\n              0.0,1.0,0.0,\n               -s,0.0,  c);\n}\n\n// Calculates the rotation matrix of a rotation around Z axis with an angle in radians\nmat3 rotateAroundZ( in float angle )\n{\n  float s = sin(angle);\n  float c = cos(angle);\n  return mat3(  c, -s,0.0,\n                s,  c,0.0,\n              0.0,0.0,1.0);\n}\n\n// Calculate rotation by given yaw and pitch angles (in degrees!)\nmat3 rotationMatrix(in float yaw, in float pitch, in float roll)\n{\n  return rotateAroundZ(deg2rad(yaw)) *\n         rotateAroundY(deg2rad(-pitch)) *\n         rotateAroundX(deg2rad(roll));\n}\n\n// Get fisheye camera ray from screen coordinates\n#ifdef MAP_FISHEYE\nfloat fisheye_direction(out vec3 rd)\n{\n  // Move screen coordinates to the center, so\n  // it is bound to [-0.5,-0.5] and [0.5,0.5]\n  vec2 uv = gl_FragCoord.xy / iResolution.xy - vec2(0.5);\n\n  // Calculate polar coordinates (angle phi and length)\n  float phi = atan(uv.x,uv.y);\n  float l = length(uv);\n\n  if (l > 0.5)\n  {\n    // Return -1.0 because the calculated polar coordinates are\n    // outside the half sphere\n    return -1.0;\n  }\n\n  // Calculate ray direction\n  float theta  = l * PI;\n  rd = normalize(vec3(sin(theta)*cos(phi),sin(theta)*sin(phi),cos(theta)));\n\n  // Formulas are on wikipedia:\n  // https://en.wikipedia.org/wiki/Polar_coordinate_system\n  return 1.0;\n}\n#endif\n\n\n// Calculate camera ray in equirectangular direction from screen coordinates\n#ifdef MAP_EQUIRECTANGULAR\nfloat equirectangular_direction(out vec3 rd)\n{\n  vec2 uv = gl_FragCoord.xy / iResolution.xy;\n\n  // Calculate azimuthal and polar angles from screen coordinates\n  float theta =  uv.t * PI,\n        phi =  uv.s * 2.0 * PI;\n\n  // Calculate ray directions from polar and azimuthal angle\n  rd = vec3(sin(theta) * cos(phi), sin(theta) * sin(phi), cos(theta));\n\n  // formulas are on wikipedia:\n  // https://en.wikipedia.org/wiki/Spherical_coordinate_system\n  return 1.0;\n}\n#endif\n\n\n// Calculate camera ray direction in equirectangular\nfloat direction(out vec3 rd)\n{\n  // Select mapping mode based on input parameter\n#ifdef MAP_EQUIRECTANGULAR\n  if (map_mode() == MAP_EQUIRECTANGULAR)\n  {\n    return equirectangular_direction(rd);\n  }\n#endif\n#ifdef MAP_FISHEYE\n  if (map_mode() == MAP_FISHEYE)\n  {\n    return fisheye_direction(rd);\n  }\n#endif\n  return -1.0;\n}\n\n\n// Calculate camera ray with rotation\nfloat direction(float roll, float pitch, float yaw, out vec3 rd)\n{\n  if (direction(rd) < 0.0)\n  {\n    return -1.0;\n  }\n  // Rotate the ray direction to have camera rotation with\n  // pitch, yaw and roll angles\n  rd *= rotateAroundZ(yaw)*rotateAroundY(pitch)*rotateAroundX(roll);\n  return 1.0;\n}\n\n// END Code section for spherical translation\n//////////////////////////////////////////////////\n\n\n\n//////////////////////////////////////////////////\n// Code section from dila\'s raymarch tutorial\n\n\n// Output resolution\n\n// Current TIME\n\n//map function, core of all the ray marching shaders. They return a scalar value, given a 3D point.\nfloat map(vec3 p){\n    //instancing:\n    // you transform the space so it\'s a repeating coordinate system\n    vec3 q = fract(p) * 2.0 -1.0;\n\n    //sphere map function is the length of the point minus the radius\n    //it\'s negative on the inside of the sphere and positive on the outside and 0 on the surface.\n    float radius = sphere_size;\n  return length(q) - radius;\n}\n\n//we use a numerical marching algorithim called trace\n//o = origin\n//r = ray to march along\n//t = intersection along the ray\nfloat trace(vec3 o, vec3 r){\n    float t = 0.0;\n    for (int i =0; i <32; i++){\n        //origin + ray*t = where we are along the ray;\n        // we step along the ray in variable length segments,\n      vec3 p = o+r*t;\n        //until we gradual converge on the intersection and evaluate the map function at that point\n        float d=map(p);\n        //we add that to t\n        // the smaller the 0.5 value, the less accurate the map function is\n        t += d * 0.5;\n    }\n     return t;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\n    ////////////////////////////////////////\n    // This commented out code section explains how setup\n    // a camera ray for standard perspective camera.\n    // For a fisheye or equirectangular camera, this is different.\n    // The calculation is done in the equirectangular_direction or\n    // fisheye_direction function.\n  // vec2 uv = fragCoord.xy / iResolution.xy;\n    //transform the cordinates to -1 to 1, instead of 0 to 1\n    // uv = uv * 2.0 - 1.0;\n    // correct the aspect ratio\n    // uv.x *= iResolution.x / iResolution.y;\n\n    //r = ray\n    // it needs to be normalized so it doesn\'t poke through the geometry when it\'s really close to the camera\n    //the z cordinate is 1.0, that\'s how you project the 2D coordinate into 3D space,\n    //you just decide the z value, which determines the field of view of the camera\n    // smaller z = higher fov. 1.0 = 90 degrees\n    //vec3 r = normalize(vec3(uv,1.0));\n\n    //rotation around the y axis\n    //you have to look up on wikipedia what this is\n    // float the= iTime*.25;\n    //r.xz *= mat2(cos(the), -sin(the), sin(the), cos(the));\n    // END of commented out section for generating a perspective view camera ray\n    ////////////////////////////////////////\n\n    // Spherical ray generation code\n    // This is entry point where the generation of\n    // camera ray in spherical direction happens!\n    /////////////////////////////////////////////////\n    vec3 r;\n    // Calculate ray direction with camera rotation\n    if (direction(\n        deg2rad(camera_roll),\n        deg2rad(camera_pitch()),\n        deg2rad(camera_yaw()),r) != 1.0) {\n      // Transparent pixel if ray direction is not valid for screen coordinates\n      fragColor = vec4(0.0,0.0,0.0,0.0);\n      return;\n    }\n\n    // the sphere is at (0.0,0.0,0.0)\n    vec3 o = vec3(0.0,0.0, iTime);\n\n    //trace from the origin along the ray to find the intersection from our map function\n    float t = trace(o, r);\n    // simple fogging funcition to darken things the further away they are\n    float fog = 1.0 / (1.0 + t * t * 0.1);\n\n    vec3 fc = vec3(fog);\n\n  fragColor = vec4(fc,1.0);\n}\n\n\n\n\nvoid main(void) {\n    mainImage(gl_FragColor, gl_FragCoord.xy);\n}'}});